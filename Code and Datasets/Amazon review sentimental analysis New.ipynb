{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prath\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\prath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "os.makedirs('images', exist_ok=True)\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Original shape: (524, 16)\n",
      "Cleaning data...\n",
      "Shape after removing empty reviews: (524, 16)\n",
      "Sample shape: (500, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "df = pd.read_csv('amazon`.csv', index_col=0)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "print(\"Cleaning data...\")\n",
    "df = df[df['reviewText'].notna() & (df['reviewText'].str.strip() != '')]\n",
    "print(f\"Shape after removing empty reviews: {df.shape}\")\n",
    "\n",
    "df = df.sample(n=min(500, len(df)), random_state=42)\n",
    "print(f\"Sample shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n",
      "Final shape after preprocessing: (500, 16)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters but keep basic punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', '', text)\n",
    "    \n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"Preprocessing text...\")\n",
    "df['cleaned_text'] = df['reviewText'].apply(preprocess_text)\n",
    "df = df[df['cleaned_text'].str.len() > 0]\n",
    "print(f\"Final shape after preprocessing: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing sentiment analyzer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.6.0+cu124 with CUDA 1204 (you have 2.6.0+cpu)\n",
      "    Python  3.10.11 (you have 3.10.16)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInitializing sentiment analyzer...\")\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing sentiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 11.02it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnalyzing sentiment...\")\n",
    "results = []\n",
    "for text in tqdm(df['cleaned_text']):\n",
    "    try:\n",
    "        result = sentiment_analyzer(text[:512])[0]\n",
    "        # Convert 5-star rating to sentiment\n",
    "        rating = int(result['label'].split()[0])\n",
    "        if rating >= 4:\n",
    "            sentiment = 'POSITIVE'\n",
    "        else:\n",
    "            sentiment = 'NEGATIVE'\n",
    "        results.append({\n",
    "            'sentiment': sentiment,\n",
    "            'score': result['score']\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing text: {str(e)}\")\n",
    "        results.append({'sentiment': 'NEGATIVE', 'score': 0.5})\n",
    "\n",
    "df['predicted_sentiment'] = [r['sentiment'] for r in results]\n",
    "df['sentiment_score'] = [r['score'] for r in results]\n",
    "\n",
    "df['true_sentiment'] = df['overall'].apply(lambda x: 'POSITIVE' if x >= 4 else 'NEGATIVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Distribution:\n",
      "predicted_sentiment\n",
      "POSITIVE    402\n",
      "NEGATIVE     98\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.78      0.95      0.85        80\n",
      "    POSITIVE       0.99      0.95      0.97       420\n",
      "\n",
      "    accuracy                           0.95       500\n",
      "   macro avg       0.88      0.95      0.91       500\n",
      "weighted avg       0.96      0.95      0.95       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(df['predicted_sentiment'].value_counts())\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    df['true_sentiment'],\n",
    "    df['predicted_sentiment'],\n",
    "    target_names=['NEGATIVE', 'POSITIVE']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis complete! Check the generated plots and classification report.\n"
     ]
    }
   ],
   "source": [
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='predicted_sentiment')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.savefig('images/sentiment_distribution_v1.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot sentiment scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='sentiment_score', hue='predicted_sentiment', bins=20)\n",
    "plt.title('Sentiment Score Distribution')\n",
    "plt.savefig('images/sentiment_scores_v1.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAnalysis complete! Check the generated plots and classification report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
